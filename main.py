import datetime
import os
import sys
import time
import traceback

from utils.pdf_processor import convert_pdf_to_images, pdf_balance
from utils.ocr_engine import img_to_md
from utils.file_utils import save_to_json
import boto3
from pymysql import Connect
from concurrent.futures import ThreadPoolExecutor


from dotenv import load_dotenv

# Âä†ËΩΩÁéØÂ¢ÉÂèòÈáè
load_dotenv()


# def process_single_pdf(pdf_path, lang):
#     if not os.path.exists(pdf_path):
#         print(f"ÈîôËØØ: Êñá‰ª∂‰∏çÂ≠òÂú® -> {pdf_path}")
#         return
#
#     # 1. PDF ËΩ¨ ÂõæÁâá
#     # ËøîÂõûÔºöÊâÄÊúâÂõæÁâáË∑ØÂæÑÂàóË°®ÔºåÂíåÂõæÁâáÊâÄÂú®ÁöÑÊñá‰ª∂Â§πË∑ØÂæÑ
#     img_paths, output_dir = convert_pdf_to_images(pdf_path)
#
#     # ÂáÜÂ§á JSON Êï∞ÊçÆÁªìÊûÑ
#     # pdf_name = os.path.splitext(os.path.basename(pdf_path))[0]
#     result_data = {
#         "filename": os.path.basename(pdf_path),
#         "total_pages": len(img_paths),
#         "pages": []
#     }
#     print(result_data)
#
#     print(f"\nüöÄ ÂºÄÂßã OCR ËØÜÂà´ ({len(img_paths)} È°µÔºåËØ≠Ë®Ä{lang})...")
#
#     # 2. ÈÅçÂéÜÂõæÁâáËøõË°å OCR
#     for idx, img_path in enumerate(img_paths):
#         page_num = idx + 1
#         print(f"[{page_num}/{len(img_paths)}] Â§ÑÁêÜ‰∏≠...")
#
#         # Ë∞ÉÁî® Gemini
#         md_content = img_to_md(img_path, lang)
#
#         # ÊãºË£ÖÂçïÈ°µÊï∞ÊçÆ
#         page_data = {
#             "page": page_num,
#             "image_path": img_path,
#             "content": md_content
#         }
#         result_data["pages"].append(page_data)
#
#     # 3. ‰øùÂ≠ò‰∏∫ JSON
#     # JSON Â∞Ü‰øùÂ≠òÂú® output/Êñá‰ª∂Âêç/Êñá‰ª∂Âêç.json
#     save_json_path = str(pdf_path)[:-4].replace('upload', 'result')
#
#     json_output_path = os.path.join(save_json_path, f"pdf_new.json")
#     print(json_output_path)
#     save_to_json(result_data, json_output_path)
#
#     print("\n‚ú® ÂÖ®ÈÉ®ÂÆåÊàêÔºÅ")
#     return output_dir, len(img_paths)


MAX_WORKERS = 5


def process_page_wrapper(args):
    """
    ÂåÖË£ÖÂáΩÊï∞ÔºåÁî®‰∫éÂú®Á∫øÁ®ãÊ±†‰∏≠ËøêË°å„ÄÇ
    Êé•Êî∂‰∏Ä‰∏™ÂÖÉÁªÑÂèÇÊï∞ (Á¥¢Âºï, ÂõæÁâáË∑ØÂæÑ, ËØ≠Ë®Ä, ÊÄªÈ°µÊï∞)
    """
    idx, img_path, lang, total_pages = args
    page_num = idx + 1

    print(f"‚ö° [Á∫øÁ®ãÂêØÂä®] Á¨¨ {page_num}/{total_pages} È°µÂºÄÂßãÂ§ÑÁêÜ...")

    # Ë∞ÉÁî®Ê†∏ÂøÉ OCR ÂáΩÊï∞
    # Ê≥®ÊÑèÔºöimg_to_md ÂáΩÊï∞ÂÜÖÈÉ®Â∑≤ÁªèÂåÖÂê´‰∫ÜÈáçËØïÊú∫Âà∂ÔºåËøôÈáåÁõ¥Êé•Ë∞ÉÁî®Âç≥ÂèØ
    md_content = img_to_md(img_path, lang)

    print(f"‚úÖ [Á∫øÁ®ãÂÆåÊàê] Á¨¨ {page_num}/{total_pages} È°µÂ§ÑÁêÜÂÆåÊØï")

    # ËøîÂõûÁªìÊûÑÂåñÁöÑÂçïÈ°µÊï∞ÊçÆ
    return {
        "page": page_num,
        "image_path": img_path,
        "content": md_content
    }


def process_single_pdf(pdf_path, lang):
    if not os.path.exists(pdf_path):
        print(f"ÈîôËØØ: Êñá‰ª∂‰∏çÂ≠òÂú® -> {pdf_path}")
        return

    # 1. PDF ËΩ¨ ÂõæÁâá
    # (ÂÅáËÆæ convert_pdf_to_images Â∑≤ÁªèÂú®‰Ω†ÁöÑ‰ª£Á†Å‰∏ä‰∏ãÊñá‰∏≠ÂÆö‰πâÂ•Ω‰∫Ü)
    try:
        img_paths, output_dir = convert_pdf_to_images(pdf_path)
    except Exception as e:
        print(f"PDF ËΩ¨ÂõæÁâáÂ§±Ë¥•: {e}")
        return

    # ÂáÜÂ§á JSON Êï∞ÊçÆÁªìÊûÑ
    result_data = {
        "filename": os.path.basename(pdf_path),
        "total_pages": len(img_paths),
        "pages": []  # ËøôÈáåÁöÑÊï∞ÊçÆÁ®çÂêéÂ°´ÂÖÖ
    }

    print(result_data)
    print(f"\nüöÄ ÂºÄÂßãÂ§öÁ∫øÁ®ã OCR ËØÜÂà´ ({len(img_paths)} È°µÔºåÂπ∂ÂèëÊï∞: {MAX_WORKERS})...")

    # 2. ÂáÜÂ§áÂ§öÁ∫øÁ®ã‰ªªÂä°ÂèÇÊï∞
    # Â∞ÜÈúÄË¶ÅÁöÑÂèÇÊï∞ÊâìÂåÖÊàêÂÖÉÁªÑÂàóË°®
    tasks = [(idx, img_path, lang, len(img_paths)) for idx, img_path in enumerate(img_paths)]

    # 3. ÊâßË°åÂ§öÁ∫øÁ®ãÊ±†
    # ‰ΩøÁî® map ÊñπÊ≥ïÂèØ‰ª•‰øùËØÅËøîÂõûÁöÑÁªìÊûúÈ°∫Â∫è‰∏é tasks ÁöÑÈ°∫Â∫è‰∏ÄËá¥ÔºàÂç≥ÊåâÈ°µÁ†ÅÊéíÂ∫èÔºâ
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        # executor.map ‰ºöÈòªÂ°û‰∏ªÁ∫øÁ®ãÔºåÁõ¥Âà∞ÊâÄÊúâ‰ªªÂä°ÂÆåÊàêÔºåÂπ∂ËøîÂõû‰∏Ä‰∏™Ëø≠‰ª£Âô®
        results = list(executor.map(process_page_wrapper, tasks))

    # Â∞ÜÊúâÂ∫èÁöÑÁªìÊûúËµãÂÄºÁªô result_data
    result_data["pages"] = results

    # 4. ‰øùÂ≠ò‰∏∫ JSON
    save_json_path = str(pdf_path)[:-4].replace('upload', 'result')

    # Á°Æ‰øùÁõÆÂΩïÂ≠òÂú®
    if not os.path.exists(save_json_path):
        os.makedirs(save_json_path)

    json_output_path = os.path.join(save_json_path, f"pdf_new.json")
    print(f"\nüíæ ‰øùÂ≠òÁªìÊûúÂà∞: {json_output_path}")

    # (ÂÅáËÆæ save_to_json Â∑≤ÁªèÂú®‰Ω†ÁöÑ‰ª£Á†Å‰∏ä‰∏ãÊñá‰∏≠ÂÆö‰πâÂ•Ω‰∫Ü)
    save_to_json(result_data, json_output_path)

    print("\n‚ú® ÂÖ®ÈÉ®ÂÆåÊàêÔºÅ")
    return output_dir, len(img_paths)


if __name__ == '__main__':
    region_name = os.getenv("REGION", "")
    aws_access_key_id = os.getenv("aws_access_key_id", "")
    aws_secret_access_key = os.getenv("aws_secret_access_key", "")
    QUEUE_URL = os.getenv("QUEUE_URL", "")

    sqs = boto3.client('sqs', region_name=region_name,
                       aws_access_key_id=aws_access_key_id,
                       aws_secret_access_key=aws_secret_access_key)
    # s3 = boto3.client('s3', region_name=Parameter.Parameter.REGION)

    # Âä†ËΩΩÊ®°Âûã
    print('load model')

    while True:
        print('While loop ---->')
        time.sleep(5)
        response = sqs.receive_message(QueueUrl=QUEUE_URL, MaxNumberOfMessages=1,
                                       WaitTimeSeconds=20)
        if 'Messages' in response:
            # snapshot1 = tracemalloc.take_snapshot()
            message = response['Messages'][0]
            sqs.delete_message(QueueUrl=QUEUE_URL, ReceiptHandle=message['ReceiptHandle'])
            print(message)
            file_map = eval(message['Body'])
            try:
                file_id = file_map['file_id']
                task_id = file_map['task_id']
                # layout = file_map['layout']
                pdf_path = os.path.join('/usr/local/src/s3mnt/new_backend/upload', task_id, f"{file_id}.pdf")
                user_id = file_map['user_id']
                parameter = file_map['parameter']
                lang = file_map['lang']

                # Êï∞ÊçÆÂ∫ìÈÖçÁΩÆ
                setting_sql = {'host': os.getenv("host", ""), 'port': int(os.getenv("port", "")),
                               'user': os.getenv("user", ""),
                               'password': os.getenv("password", ""), 'database': os.getenv("database", "")}

                with Connect(**setting_sql) as conn:
                    cursor = conn.cursor()
                    sql = f'UPDATE file_result SET ' \
                          f'queue_time="{datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")}" ' \
                          f'WHERE file_id="{file_id}" and task_id="{task_id}"'
                    print(sql)
                    cursor.execute(sql)
                    conn.commit()

                # Ëß£Êûêpdf
                image_path, pdf_page_num = process_single_pdf(pdf_path=pdf_path, lang=lang)

                # ËÆ°Ë¥π
                pdf_balance(image_path, task_id, file_id, user_id, pdf_page_num, setting_sql)

                print('Êâ£Ë¥πÊàêÂäü')

            except:
                print(traceback.format_exc())

