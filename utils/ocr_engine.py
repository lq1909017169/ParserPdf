# import os
# import time
# import traceback
# import google.generativeai as genai
#
# import traceback
# from PIL import Image
import io
import random
from dotenv import load_dotenv
from google.generativeai.types import HarmCategory, HarmBlockThreshold
import os
import time
import mimetypes
from google.oauth2 import service_account
import vertexai
from vertexai.generative_models import (
    GenerativeModel,
    Part,
    FinishReason,
    HarmCategory,
    HarmBlockThreshold,
    GenerationConfig,
    Image
)


# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# å‡†å¤‡ API Keys
api_keys_str = os.getenv("API_KEYS", "")
genai_name = os.getenv("GENAI_NAME", "")
API_KEYS = [
    k.strip().replace("'", "").replace('"', "")  # æ ¸å¿ƒä¿®æ”¹ï¼šå¼ºåˆ¶æ›¿æ¢æ‰å•å¼•å·å’ŒåŒå¼•å·
    for k in api_keys_str.split(',')
    if k.strip()
]


def random_genai():
    """éšæœºè·å–ä¸€ä¸ª API Key"""
    try:
        if not API_KEYS:
            raise ValueError("API key list is empty")
        api_key_index = random.randint(0, len(API_KEYS) - 1)
        api_key = API_KEYS[api_key_index]
        return api_key
    except Exception as e:
        print(f"Error selecting API key: {e}")
        raise


def create_generation_config():
    return {
        "temperature": 0.1,  # ä¿æŒä½æ¸©åº¦ä»¥ç¡®ä¿ OCR å‡†ç¡®æ€§
        "top_p": 0.95,
        "top_k": 40,
        "max_output_tokens": 8192,
        "response_mime_type": "text/plain",
    }


# ä½ çš„ JSON å¯†é’¥è·¯å¾„
KEY_PATH = "/usr/local/src/pypro/ParserPdf/utils/key_json/key.json"

# ä½ çš„é¡¹ç›® ID
PROJECT_ID = "eyeweb-wb-ys"

# ã€å…³é”®ä¿®æ”¹ã€‘Gemini 3 Preview é€šå¸¸éœ€è¦ global åŒºåŸŸ
# LOCATION = "global"
LOCATION = "us-central1"

# ä½¿ç”¨ä½ éªŒè¯æˆåŠŸçš„æ¨¡å‹
MODEL_NAME = "gemini-3-pro-preview"

# ================= åˆå§‹åŒ– =================
try:
    print(f"ğŸ”„ Initializing Vertex AI ({LOCATION})...")
    if os.path.exists(KEY_PATH):
        credentials = service_account.Credentials.from_service_account_file(KEY_PATH)
        vertexai.init(project=PROJECT_ID, location=LOCATION, credentials=credentials)
        print(f"âœ… Vertex AI initialized using {MODEL_NAME}")
    else:
        print(f"âš ï¸ Key file missing at {KEY_PATH}")
except Exception as e:
    print(f"âŒ Init failed: {e}")


# =========================================

def get_safety_settings():
    """æ”¾å®½å®‰å…¨é™åˆ¶"""
    return {
        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
    }


def img_to_md(image_path, lang="en"):
    """
    ä¼˜åŒ–åçš„ OCR å‡½æ•°ï¼š
    1. ä½¿ç”¨ Gemini 3 Pro Preview
    2. ä½¿ç”¨ Vertex AI Image ç±»åŠ è½½
    3. åŒ…å«é’ˆå¯¹ç›®å½•é¡µå’Œç‰ˆæƒé¡µçš„è‡ªåŠ¨ä¿®å¤é€»è¾‘
    """
    # print(f"\n========== PROCESSING: {os.path.basename(image_path)} ==========")

    if not os.path.exists(image_path):
        return "Error: Image file not found."

    max_retries = 3

    for attempt in range(max_retries):
        try:
            # 1. ä½¿ç”¨ SDK åŸç”Ÿæ–¹å¼åŠ è½½å›¾ç‰‡ (ä»£ç æ›´ç®€æ´)
            img = Image.load_from_file(image_path)

            # 2. åŠ¨æ€ Prompt ç­–ç•¥ (åº”å¯¹æ­»å¾ªç¯å’Œç‰ˆæƒæ‹¦æˆª)

            # --- Attempt 0: æ­£å¸¸æ¨¡å¼ ---
            prompt_parts = [
                f"ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ OCR å·¥å…·ã€‚è¯·è¯†åˆ«å›¾ä¸­çš„{lang}æ–‡å­—å¹¶è½¬æ¢ä¸º Markdownã€‚",
                "å¦‚æœæ˜¯æ•°å­¦å…¬å¼ï¼Œè¯·ä¸¥æ ¼ä½¿ç”¨ LaTeX æ ¼å¼ï¼ˆå¦‚ $$...$$ï¼‰ã€‚",
                "é‡åˆ°ç›®å½•é¡µçš„å¼•å¯¼ç‚¹ï¼ˆ......ï¼‰ï¼Œ**å¿…é¡»å¿½ç•¥**ï¼Œç›´æ¥è¾“å‡ºæ–‡å­—å’Œé¡µç ã€‚",
                "å¦‚æœå›¾ç‰‡ä¸­æ²¡æœ‰ä»»ä½•å…ƒç´ ï¼Œè¿”å›""å³å¯",
                img  # å›¾ç‰‡å¯¹è±¡ç›´æ¥æ”¾å…¥åˆ—è¡¨
            ]

            # --- Attempt 1: ä¸¥æ ¼æ¨¡å¼ (é’ˆå¯¹ç›®å½•é¡µæ­»å¾ªç¯) ---
            if attempt == 1:
                print(f"[Warning] Retrying {os.path.basename(image_path)} (Strict Mode)...")
                prompt_parts = [
                    "æå–æ–‡å­—ã€‚**ä¸¥é‡è­¦å‘Šï¼šç»å¯¹ç¦æ­¢è¾“å‡ºä»»ä½•è¿ç»­çš„ç‚¹å·(......)ï¼é‡åˆ°è¯·ç›´æ¥åˆ é™¤ï¼**",
                    "å¿½ç•¥æ‰€æœ‰è£…é¥°æ€§ç¬¦å·ï¼Œåªä¿ç•™æ–‡æœ¬å’Œæ•°å­—ã€‚",
                    img
                ]

            # --- Attempt 2: é˜²ç‰ˆæƒæ¨¡å¼ (é’ˆå¯¹å‚è€ƒæ–‡çŒ®é¡µ) ---
            if attempt == 2:
                print(f"[Warning] Retrying {os.path.basename(image_path)} (Anti-Recitation Mode)...")
                prompt_parts = [
                    "You are a bibliographic data assistant.",
                    "Extract references from the image into Markdown.",
                    "**IMPORTANT RULE**: You MUST **bold** the title of every paper/section to create a structured dataset.",
                    "Example: Author. **Paper Title**. Year.",
                    img
                ]

            # 3. åŠ è½½æ¨¡å‹
            model = GenerativeModel(MODEL_NAME)

            # 4. å‘é€è¯·æ±‚
            # æ³¨æ„ï¼šGemini 3 é€šå¸¸ä¸éœ€è¦ System Instructionï¼Œç›´æ¥å†™åœ¨ Prompt é‡Œæ•ˆæœæ›´å¥½
            response = model.generate_content(
                prompt_parts,
                generation_config=GenerationConfig(
                    # é‡è¯•æ—¶é™ä½æ¸©åº¦ï¼Œå¢åŠ ç¡®å®šæ€§
                    temperature=0.1 if attempt < 2 else 0.4,
                    top_p=0.95,
                    max_output_tokens=8192,
                ),
                safety_settings=get_safety_settings()
            )

            # 5. ç»“æœæ ¡éªŒ
            if not response.candidates:
                if attempt < max_retries - 1: continue
                return "Error: No candidates."

            candidate = response.candidates[0]
            finish_reason = candidate.finish_reason

            # === æˆåŠŸè·å–æ–‡æœ¬ ===
            if candidate.content and candidate.content.parts:
                text = candidate.content.parts[0].text

                # å¦‚æœæ˜¯å› ä¸º Token è€—å°½ (å¯èƒ½è¿˜åœ¨ç”»ç‚¹)ï¼Œå°è¯•æˆªæ–­ä¿®å¤
                if finish_reason == FinishReason.MAX_TOKENS:
                    text = text.rstrip('. ')

                return text

            # === å¤±è´¥å¤„ç† ===
            # print(f"[Debug] Attempt {attempt+1} Failed. Reason Code: {finish_reason}")

            # é‡åˆ°ç‰ˆæƒ(RECITATION=4) æˆ– æ­»å¾ªç¯(MAX_TOKENS=2) -> ç»§ç»­å¾ªç¯
            if finish_reason in [FinishReason.RECITATION, FinishReason.MAX_TOKENS, FinishReason.SAFETY]:
                time.sleep(1)
                continue

            if attempt < max_retries - 1:
                time.sleep(1)
                continue

            return f"Error: Blocked with reason {finish_reason}"

        except Exception as e:
            # print(f"[Exception] {e}")
            if attempt < max_retries - 1:
                time.sleep(2)
                continue
            return 'Please parse again'

    return "Error: Failed after retries."


# def get_safety_settings():
#     return {
#         HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
#         HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
#         HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
#         HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
#     }
#
#
# def img_to_md(image_path, lang="en"):
#     # ... å‰é¢çš„åˆå§‹åŒ–ä»£ç ä¸å˜ ...
#     api_key = random_genai()
#     max_retries = 5
#
#     for attempt in range(max_retries):
#         try:
#             genai.configure(api_key=api_key)
#             img = PIL.Image.open(image_path)
#
#             # === é»˜è®¤é…ç½® ===
#             temp = 0.1
#             sys_instruction = f"ä½ æ˜¯ä¸€ä¸ª OCR å·¥å…·ã€‚è¯·è¯†åˆ«å›¾ä¸­çš„{lang}æ–‡å­—å¹¶è½¬ä¸º Markdownã€‚"
#             prompt_text = "è¯†åˆ«å›¾ç‰‡å†…å®¹ã€‚"
#
#             # === ã€å…³é”®ç­–ç•¥ä¿®æ”¹ã€‘ ===
#
#             # ç¬¬ä¸€æ¬¡é‡è¯• (Attempt 1): ä¸¥å‰æ¨¡å¼ (é’ˆå¯¹ç›®å½•æ­»å¾ªç¯)
#             if attempt == 1:
#                 temp = 0.0
#                 sys_instruction += " **å¿½ç•¥æ‰€æœ‰è¿ç»­çš„ç‚¹å·(......)**ã€‚"
#
#             # ç¬¬äºŒæ¬¡é‡è¯• (Attempt 2): ã€é˜²ç‰ˆæƒæ¨¡å¼ - é’ˆå¯¹å‚è€ƒæ–‡çŒ®ã€‘
#             # å¦‚æœæ˜¯å‚è€ƒæ–‡çŒ®é¡µï¼Œå¼ºåˆ¶è¦æ±‚æ”¹å˜æ ¼å¼ï¼Œç ´åæŒ‡çº¹åŒ¹é…
#             if attempt == 2:
#                 print(f"[Warning] å¯ç”¨å‚è€ƒæ–‡çŒ®ç‰¹æ®Šæ¨¡å¼ (Anti-Recitation Mode)...")
#                 temp = 0.3  # ç¨å¾®å¢åŠ éšæœºæ€§
#
#                 # æ ¸å¿ƒ Trickï¼šå‘Šè¯‰æ¨¡å‹è¿™æ˜¯ä¸€ä¸ªâ€œæ ¼å¼åŒ–ä»»åŠ¡â€è€Œä¸æ˜¯â€œè¯»å–ä»»åŠ¡â€
#                 sys_instruction = (
#                     f"You are a bibliographic data assistant. "
#                     f"The image contains a list of academic references. "
#                     f"Your task is to extract them into a Markdown list. "
#                     f"**IMPORTANT RULE**: To ensure readability, you MUST **bold** the title of every paper."
#                     f"For example: Author Name. **Paper Title**. Publisher."
#                 )
#                 prompt_text = "Extract references. Remember to **bold** the titles to differentiate them from authors."
#
#             model = genai.GenerativeModel(
#                 model_name=genai_name,
#                 generation_config={
#                     "temperature": temp,
#                     "top_p": 0.95,
#                     "max_output_tokens": 8192,
#                 },
#                 system_instruction=sys_instruction,
#                 safety_settings=get_safety_settings()
#             )
#
#             response = model.generate_content([prompt_text, img])
#
#             if not response.candidates:
#                 if attempt < max_retries - 1: continue
#                 return "Error: No candidates."
#
#             candidate = response.candidates[0]
#             finish_reason = candidate.finish_reason
#
#             # æˆåŠŸè·å–
#             if candidate.content and candidate.content.parts:
#                 text = candidate.content.parts[0].text
#                 return text
#
#             # å¤±è´¥å¤„ç†
#             print(f"[Debug] Attempt {attempt + 1} Failed. Reason: {finish_reason}")
#
#             # å¦‚æœæ˜¯ç‰ˆæƒæ‹¦æˆª (4)ï¼Œè®©å¾ªç¯ç»§ç»­ï¼Œè‡ªç„¶ä¼šè¿›å…¥ attempt=2 çš„é€»è¾‘
#             if finish_reason == 4 or finish_reason == 3:
#                 time.sleep(1)
#                 continue
#
#             # å¦‚æœæ˜¯æ­»å¾ªç¯ (2)ï¼Œä¹Ÿç»§ç»­
#             if finish_reason == 2:
#                 time.sleep(1)
#                 continue
#
#         except Exception as e:
#             print(f"[Exception] {e}")
#             time.sleep(1)
#             continue
#
#     return "Error: Failed to parse page 19."


# ä¸‹é¢ä¸ºæ—§ç‰ˆ
# def create_generation_config():
#     return {
#         "temperature": 0.1,
#         "top_p": 0.95,
#         "top_k": 40,
#         "max_output_tokens": 100000,
#         "response_mime_type": "text/plain",
#     }
#
#
# def get_safety_settings():
#     return {
#         HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
#         HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
#         HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
#         HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
#     }
#
#
# def upload_to_gemini(api_key, path, mime_type=None):
#     """ä¸Šä¼ æ–‡ä»¶åˆ° Gemini"""
#     genai.configure(api_key=api_key)
#     file = genai.upload_file(path, mime_type=mime_type)
#     print(f"Uploaded file '{file.display_name}' as: {file.uri}")
#     return file
#
#
# def wait_for_files_active(files):
#     """ç­‰å¾…æ–‡ä»¶å¤„ç†å®Œæ¯•ï¼ˆGemini API å¯¹äºæŸäº›å¤§æ–‡ä»¶éœ€è¦å¤„ç†æ—¶é—´ï¼‰"""
#     print("Waiting for file processing...")
#     for name in (file.name for file in files):
#         file = genai.get_file(name)
#         while file.state.name == "PROCESSING":
#             print(".", end="", flush=True)
#             time.sleep(2)
#             file = genai.get_file(name)
#         if file.state.name != "ACTIVE":
#             raise Exception(f"File {file.name} failed to process")
#     print("...all files ready")
#
#
# def img_to_md(image_path, lang):
#     api_key = random_genai()
#     print('Using api_key ending in:', api_key[-4:])  # æ‰“å°Keyçš„åå››ä½ç”¨äºè°ƒè¯•ï¼Œä¸æ‰“å°å…¨è²Œ
#
#     if not api_key:
#         return "Error: No API key available."
#
#     try:
#         # é…ç½® API
#         genai.configure(api_key=api_key)
#
#         # 1. ä¸Šä¼ å›¾ç‰‡
#         # æ³¨æ„ï¼šå¦‚æœå›¾ç‰‡éå¸¸å°ï¼Œå…¶å®å¯ä»¥ç›´æ¥è½¬ bytes å‘é€ï¼Œä½†è¿™é‡Œä¿ç•™ä½ çš„ upload_file é€»è¾‘
#         gemini_image = upload_to_gemini(api_key, image_path, mime_type="image/png")
#
#         # ç¡®ä¿æ–‡ä»¶å·²å°±ç»ªï¼ˆè™½ç„¶å›¾ç‰‡é€šå¸¸å¾ˆå¿«ï¼Œä½†åŠ ä¸Šè¿™ä¸ªé€»è¾‘æ›´ç¨³å¥ï¼‰
#         wait_for_files_active([gemini_image])
#
#         # 2. è®¾ç½® System Instruction
#         # è¿™é‡Œçš„æŒ‡ä»¤éå¸¸å…³é”®ï¼Œè¦æ±‚å®ƒå¼ºåˆ¶è¾“å‡º Markdownï¼Œå¹¶å¤„ç†å…¬å¼
#         system_instruction = (
#             f"ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ OCR åŠ©æ‰‹ã€‚è¯·è¯†åˆ«å›¾ç‰‡ä¸­çš„æ‰€æœ‰å†…å®¹ï¼Œå›¾ä¸­è¯­è¨€ä¸º:{lang},è¯·ä»¥{lang}è¯­è¨€è¿”å›å¹¶å°†å…¶è½¬æ¢ä¸ºæ ‡å‡†çš„ "
#             f"Markdown æ ¼å¼è¿”å›ã€‚å¦‚æœæ˜¯è¡¨æ ¼ï¼Œè¯·ä½¿ç”¨ Markdown è¡¨æ ¼è¯­æ³•ã€‚å¦‚æœæ˜¯æ•°å­¦å…¬å¼ï¼Œè¯·ä½¿ç”¨ LaTeX æ ¼å¼ï¼ˆè¡Œå†…å…¬å¼ç”¨ $ åŒ…è£¹ï¼Œç‹¬å ä¸€è¡Œç”¨ $$ åŒ…è£¹ï¼‰ã€‚"
#             f"ä¸è¦åŒ…å«ä»»ä½•å¼€åœºç™½æˆ–ç»“æŸè¯­ï¼Œåªè¿”å›è½¬æ¢åçš„å†…å®¹ã€‚"
#         )
#
#         # 3. åˆ›å»ºæ¨¡å‹
#         generation_config = create_generation_config()
#         model = genai.GenerativeModel(
#             model_name=genai_name,
#             generation_config=generation_config,
#             system_instruction=system_instruction,
#             safety_settings=get_safety_settings()
#         )
#
#         prompt = "è¯·å°†è¿™å¼ å›¾ç‰‡çš„å†…å®¹ç²¾å‡†è½¬æ¢ä¸º Markdown æ ¼å¼ã€‚"
#
#         response = model.generate_content([gemini_image, prompt])
#
#         try:
#             return response.text
#         except:
#             print(response.candidates)
#             print(traceback.format_exc())
#             print(f"DEBUG: Finish Reason: {response.candidates[0].finish_reason}")
#             # å¼ºè¡Œè·å–æˆªæ–­å†…å®¹
#             if response.candidates and response.candidates[0].content.parts:
#                 return response.candidates[0].content.parts[0].text
#             return ""
#
#     except Exception:
#         print(traceback.format_exc())
#         return 'Please parse again'


if __name__ == '__main__':
    pass
    # import vertexai
    # from google.oauth2 import service_account
    # from vertexai.generative_models import GenerativeModel, Image
    #
    # KEY_PATH = "/usr/local/src/pypro/ParserPdf/utils/key_json/key.json"
    # PROJECT_ID = "eyeweb-wb-ys"
    # LOCATION = "global"
    #
    # credentials = service_account.Credentials.from_service_account_file(KEY_PATH)
    # vertexai.init(project=PROJECT_ID, location=LOCATION, credentials=credentials)
    #
    # image = Image.load_from_file(r"/usr/local/src/pypro/ParserPdf/img/gongshi.png")
    # vision_model = GenerativeModel("gemini-3-pro-preview")
    #
    # vision_model.generate_content(["ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ OCR å·¥å…·ï¼Œè¯†åˆ«å›¾ç‰‡å†…å®¹å¹¶è½¬æ¢ä¸º Markdownã€‚", image])